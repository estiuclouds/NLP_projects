{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабараторная работа №1. Сорокин Семен и Мотов Алексей 14фпл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 0.\n",
    "Вариант №9.\n",
    "Собрание оперативных данных о сферах: жилой, коммерческой, промышленной и земледельческой - для нахождения аккуратности (точности) потребления электричества в Tamil Nadu Around Thanajvur.\n",
    "Характеристики дата-сета: Многовариантный\n",
    "Количество сущностей: 45781\n",
    "Сфера:Жизнь(проживание)\n",
    "Характеристика атрибутов: реальные\n",
    "Количество атрибутов:5\n",
    "Дата публикации:2013-12-22\n",
    "Пути решения:Классификация, Регрессия, Класстеризация\n",
    "Отсутствующие параметры: нет\n",
    "Количество Web Hits:31879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.Получение первичных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForkVA</th>\n",
       "      <th>ForkW</th>\n",
       "      <th>Type</th>\n",
       "      <th>Sector</th>\n",
       "      <th>ServiceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865936</td>\n",
       "      <td>0.143763</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129804</td>\n",
       "      <td>0.088930</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061801</td>\n",
       "      <td>0.552047</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099116</td>\n",
       "      <td>0.848172</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205704</td>\n",
       "      <td>0.624722</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.164029</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.619834</td>\n",
       "      <td>0.079611</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.718472</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.344461</td>\n",
       "      <td>0.271178</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.679169</td>\n",
       "      <td>0.191223</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.381792</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.940152</td>\n",
       "      <td>0.981297</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.543696</td>\n",
       "      <td>0.210495</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.074785</td>\n",
       "      <td>0.407648</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.667057</td>\n",
       "      <td>0.441408</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.860208</td>\n",
       "      <td>0.671408</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.177475</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.107628</td>\n",
       "      <td>0.309156</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.695464</td>\n",
       "      <td>0.992786</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.622046</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.658742</td>\n",
       "      <td>0.874708</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.711535</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.721738</td>\n",
       "      <td>0.631548</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.516696</td>\n",
       "      <td>0.147568</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.164996</td>\n",
       "      <td>0.369274</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.171748</td>\n",
       "      <td>0.085911</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.261766</td>\n",
       "      <td>0.407849</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.259692</td>\n",
       "      <td>0.051687</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.604756</td>\n",
       "      <td>0.250681</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.487839</td>\n",
       "      <td>0.959527</td>\n",
       "      <td>Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>671004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45751</th>\n",
       "      <td>0.880957</td>\n",
       "      <td>0.341562</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45752</th>\n",
       "      <td>0.576744</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45753</th>\n",
       "      <td>0.645571</td>\n",
       "      <td>0.507445</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45754</th>\n",
       "      <td>0.582752</td>\n",
       "      <td>0.544649</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45755</th>\n",
       "      <td>0.767346</td>\n",
       "      <td>0.605864</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45756</th>\n",
       "      <td>0.859672</td>\n",
       "      <td>0.195399</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45757</th>\n",
       "      <td>0.389784</td>\n",
       "      <td>0.147966</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45758</th>\n",
       "      <td>0.481084</td>\n",
       "      <td>0.772099</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45759</th>\n",
       "      <td>0.031560</td>\n",
       "      <td>0.069771</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45760</th>\n",
       "      <td>0.955797</td>\n",
       "      <td>0.708938</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45761</th>\n",
       "      <td>0.781747</td>\n",
       "      <td>0.684059</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45762</th>\n",
       "      <td>0.728798</td>\n",
       "      <td>0.399608</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45763</th>\n",
       "      <td>0.305435</td>\n",
       "      <td>0.655755</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45764</th>\n",
       "      <td>0.340016</td>\n",
       "      <td>0.297167</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45765</th>\n",
       "      <td>0.812929</td>\n",
       "      <td>0.214185</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45766</th>\n",
       "      <td>0.219228</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45767</th>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.753734</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45768</th>\n",
       "      <td>0.906085</td>\n",
       "      <td>0.721175</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45769</th>\n",
       "      <td>0.508465</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45770</th>\n",
       "      <td>0.031784</td>\n",
       "      <td>0.352641</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45771</th>\n",
       "      <td>0.452340</td>\n",
       "      <td>0.847685</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45772</th>\n",
       "      <td>0.131527</td>\n",
       "      <td>0.119815</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45773</th>\n",
       "      <td>0.998798</td>\n",
       "      <td>0.434231</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45774</th>\n",
       "      <td>0.408391</td>\n",
       "      <td>0.444635</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45775</th>\n",
       "      <td>0.594639</td>\n",
       "      <td>0.741307</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45776</th>\n",
       "      <td>0.815382</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45777</th>\n",
       "      <td>0.821317</td>\n",
       "      <td>0.439967</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45778</th>\n",
       "      <td>0.523061</td>\n",
       "      <td>0.227777</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45779</th>\n",
       "      <td>0.925497</td>\n",
       "      <td>0.386428</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45780</th>\n",
       "      <td>0.763602</td>\n",
       "      <td>0.456028</td>\n",
       "      <td>University</td>\n",
       "      <td>1</td>\n",
       "      <td>800145754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45781 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ForkVA     ForkW        Type  Sector  ServiceID\n",
       "0      0.865936  0.143763        Bank       1  671004572\n",
       "1      0.129804  0.088930        Bank       1  671004572\n",
       "2      0.061801  0.552047        Bank       1  671004572\n",
       "3      0.099116  0.848172        Bank       1  671004572\n",
       "4      0.205704  0.624722        Bank       1  671004572\n",
       "5      0.164029  0.038168        Bank       1  671004572\n",
       "6      0.619834  0.079611        Bank       1  671004572\n",
       "7      0.011324  0.718472        Bank       1  671004572\n",
       "8      0.344461  0.271178        Bank       1  671004572\n",
       "9      0.679169  0.191223        Bank       1  671004572\n",
       "10     0.191592  0.381792        Bank       1  671004572\n",
       "11     0.940152  0.981297        Bank       1  671004572\n",
       "12     0.543696  0.210495        Bank       1  671004572\n",
       "13     0.074785  0.407648        Bank       1  671004572\n",
       "14     0.667057  0.441408        Bank       1  671004572\n",
       "15     0.860208  0.671408        Bank       1  671004572\n",
       "16     0.177475  0.931110        Bank       1  671004572\n",
       "17     0.107628  0.309156        Bank       1  671004572\n",
       "18     0.695464  0.992786        Bank       1  671004572\n",
       "19     0.622046  0.063885        Bank       1  671004572\n",
       "20     0.658742  0.874708        Bank       1  671004572\n",
       "21     0.029141  0.711535        Bank       1  671004572\n",
       "22     0.721738  0.631548        Bank       1  671004572\n",
       "23     0.516696  0.147568        Bank       1  671004572\n",
       "24     0.164996  0.369274        Bank       1  671004572\n",
       "25     0.171748  0.085911        Bank       1  671004572\n",
       "26     0.261766  0.407849        Bank       1  671004572\n",
       "27     0.259692  0.051687        Bank       1  671004572\n",
       "28     0.604756  0.250681        Bank       1  671004572\n",
       "29     0.487839  0.959527        Bank       1  671004572\n",
       "...         ...       ...         ...     ...        ...\n",
       "45751  0.880957  0.341562  University       1  800145754\n",
       "45752  0.576744  0.040346  University       1  800145754\n",
       "45753  0.645571  0.507445  University       1  800145754\n",
       "45754  0.582752  0.544649  University       1  800145754\n",
       "45755  0.767346  0.605864  University       1  800145754\n",
       "45756  0.859672  0.195399  University       1  800145754\n",
       "45757  0.389784  0.147966  University       1  800145754\n",
       "45758  0.481084  0.772099  University       1  800145754\n",
       "45759  0.031560  0.069771  University       1  800145754\n",
       "45760  0.955797  0.708938  University       1  800145754\n",
       "45761  0.781747  0.684059  University       1  800145754\n",
       "45762  0.728798  0.399608  University       1  800145754\n",
       "45763  0.305435  0.655755  University       1  800145754\n",
       "45764  0.340016  0.297167  University       1  800145754\n",
       "45765  0.812929  0.214185  University       1  800145754\n",
       "45766  0.219228  0.068273  University       1  800145754\n",
       "45767  0.248366  0.753734  University       1  800145754\n",
       "45768  0.906085  0.721175  University       1  800145754\n",
       "45769  0.508465  0.569024  University       1  800145754\n",
       "45770  0.031784  0.352641  University       1  800145754\n",
       "45771  0.452340  0.847685  University       1  800145754\n",
       "45772  0.131527  0.119815  University       1  800145754\n",
       "45773  0.998798  0.434231  University       1  800145754\n",
       "45774  0.408391  0.444635  University       1  800145754\n",
       "45775  0.594639  0.741307  University       1  800145754\n",
       "45776  0.815382  0.822821  University       1  800145754\n",
       "45777  0.821317  0.439967  University       1  800145754\n",
       "45778  0.523061  0.227777  University       1  800145754\n",
       "45779  0.925497  0.386428  University       1  800145754\n",
       "45780  0.763602  0.456028  University       1  800145754\n",
       "\n",
       "[45781 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "inputData = pd.read_csv('eb1.arff.csv', delimiter=',')\n",
    "inputData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.2. Проверка на отсутствующие данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: False\n",
      "Count of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Null values: {0}\".format(inputData.isnull().values.any()))\n",
    "print(\"Count of NaN values: {0}\".format(np.sum(inputData.isnull().values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForkVA       float64\n",
       "ForkW        float64\n",
       "Type          object\n",
       "Sector         int64\n",
       "ServiceID      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование категориальных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForkVA                          float64\n",
       "ForkW                           float64\n",
       "Sector                            int64\n",
       "ServiceID                         int64\n",
       "Type_AutomobileIndustry           uint8\n",
       "Type_Bank                         uint8\n",
       "Type_BpoIndustry                  uint8\n",
       "Type_CementIndustry               uint8\n",
       "Type_ChemicalIndustry             uint8\n",
       "Type_Farmers1                     uint8\n",
       "Type_Farmers2                     uint8\n",
       "Type_FertilizerIndustry           uint8\n",
       "Type_FoodIndustry                 uint8\n",
       "Type_Handlooms                    uint8\n",
       "Type_HealthCareResources          uint8\n",
       "Type_Hospital                     uint8\n",
       "Type_Hostel                       uint8\n",
       "Type_PoultryIndustry              uint8\n",
       "Type_Residential(Apartments)      uint8\n",
       "Type_Residential(individual)      uint8\n",
       "Type_Supermarket                  uint8\n",
       "Type_TextileIndustry              uint8\n",
       "Type_Theatre                      uint8\n",
       "Type_University                   uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData1 =  pd.get_dummies(inputData, columns=['Type'])\n",
    "inputData1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. Преобразование в матричную и векторную форму "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.43763000e-01,   1.00000000e+00,   6.71004572e+08,\n",
       "         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetColumn = 'ForkVA'\n",
    "\n",
    "FeatureColumns = inputData1.columns.tolist()\n",
    "FeatureColumns.remove(targetColumn)\n",
    "\n",
    "X = inputData1[FeatureColumns].values\n",
    "y = inputData1[targetColumn].values\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. Применение линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Расчет метрик (MAE, MSE, RMSE, R^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 0.2499439266021522\n",
      "MSE : 0.08329497048142051\n",
      "R^2 coefficient : 0.00032156573972175195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_predict = lr.predict(X)\n",
    "\n",
    "test_mae_error = mean_absolute_error(y, y_predict)\n",
    "test_mse_error = mean_squared_error(y, y_predict)\n",
    "test_r2_error = r2_score(y, y_predict)\n",
    "print(\"MAE : {0}\".format(test_mae_error))\n",
    "print(\"MSE : {0}\".format(test_mse_error))\n",
    "print(\"R^2 coefficient : {0}\".format(test_r2_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1: MAE : 0.25014684924414915, MSE : 0.08351200311779845, R2 : -0.0009809896083783354\n",
      "Iteration #2: MAE : 0.25081460157790625, MSE : 0.08374129662652091, R2 : -0.0006705791609185052\n",
      "Iteration #3: MAE : 0.24925549187747084, MSE : 0.08290943461404565, R2 : -0.0008145930226803877\n",
      "\n",
      "Overall: \n",
      "\tMAE : 0.25007231423317544\n",
      "\tMSE : 0.083387578119455\n",
      "\tR^2 coefficient : -0.0008220539306590761\n"
     ]
    }
   ],
   "source": [
    "MAE_list_scores = []\n",
    "MSE_list_scores = []\n",
    "R2_list_scores = []\n",
    "\n",
    "iteration_index = 0\n",
    "\n",
    "# Разделение на тестовую и тренировочную выборки\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    iteration_index+=1\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    lr.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = lr.predict(X_test)\n",
    "    \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "    current_r2 = r2_score(y_test, y_predict)\n",
    "    print(\"Iteration #{0}: MAE : {1}, MSE : {2}, R2 : {3}\".format(iteration_index, current_mae, current_mse, current_r2))\n",
    "    MAE_list_scores.append(current_mae)\n",
    "    MSE_list_scores.append(current_mse)\n",
    "    R2_list_scores.append(current_r2)\n",
    "\n",
    "# Выведем средние значения:\n",
    "print(\"\\nOverall: \")\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list_scores)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list_scores)))\n",
    "print(\"\\tR^2 coefficient : {0}\".format(np.mean(R2_list_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_error < np.mean(MSE_list_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0\n",
      "\tMAE : 0.24998504081882386\n",
      "\tMSE : 0.08332352680532208\n",
      "Degree: 1\n",
      "\tMAE : 0.2501019187719901\n",
      "\tMSE : 0.08339603242285687\n",
      "Degree: 2\n",
      "\tMAE : 0.2500668654270546\n",
      "\tMSE : 0.0833947607223043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "degreeList = []\n",
    "maeList = []\n",
    "mseList = []\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "for count, degree in enumerate(range(0,3)):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    \n",
    "    MAE_for_current_degree = []\n",
    "    MSE_for_current_degree = []\n",
    "    \n",
    "    for train_indexes, test_indexes in kf.split(X,y):\n",
    "        # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "        X_train = X[train_indexes]\n",
    "        y_train = y[train_indexes]\n",
    "    \n",
    "        # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "        X_test = X[test_indexes]\n",
    "        y_test = y[test_indexes]\n",
    "    \n",
    "        model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "        y_predict = model.predict(X_test)\n",
    "        \n",
    "        current_mae = mean_absolute_error(y_test, y_predict)\n",
    "        current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "        MAE_for_current_degree.append(current_mae)\n",
    "        MSE_for_current_degree.append(current_mse)\n",
    "    \n",
    "    print(\"Degree: {0}\".format(degree))\n",
    "    print(\"\\tMAE : {0}\".format(np.mean(MAE_for_current_degree)))\n",
    "    print(\"\\tMSE : {0}\".format(np.mean(MSE_for_current_degree)))\n",
    "    degreeList.append(degree)\n",
    "    maeList.append(np.mean(MAE_for_current_degree))\n",
    "    mseList.append(np.mean(MSE_for_current_degree))\n",
    "\n",
    "MAE_polin_degree2=maeList[2]\n",
    "MSE_polin_degree2=mseList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x907ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEWCAYAAADCeVhIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3078a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(degreeList, mseList, 'b-', label='MSE')\n",
    "plt.title('MSE Error')\n",
    "plt.ylabel('MSE Error')\n",
    "plt.xlabel('Degree of polynomial')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(degreeList, maeList, 'r', label='MAE')\n",
    "plt.title('MAE Error')\n",
    "plt.ylabel('MAE Error')\n",
    "plt.xlabel('Degree of polynomial')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  1.80757587e-18   1.40658195e-16  -5.71562416e-23   3.42789686e-12\n",
      "  -2.47743403e-20   2.10508435e-20   5.57908120e-20  -3.81228480e-22\n",
      "  -7.60126735e-20  -8.14432672e-20  -5.19594193e-20   7.79739657e-20\n",
      "   7.13473596e-20   8.27646721e-20  -1.94055218e-19  -9.43246069e-20\n",
      "  -1.08922161e-18   5.46437392e-21  -1.39092028e-20  -1.01285695e-21\n",
      "  -1.82447931e-20  -1.53017511e-20  -2.38854427e-20   1.39401224e-23\n",
      "  -1.67435746e-21  -1.53572564e-21   7.17551320e-13  -1.22857730e-20\n",
      "   7.03319954e-21   3.04768943e-20  -1.67096051e-21  -1.67049546e-20\n",
      "  -4.53895182e-21  -3.10315579e-20  -6.76502619e-21  -8.11371431e-21\n",
      "   4.97818596e-20   1.83852481e-20  -2.61258062e-21   1.01402457e-20\n",
      "   2.67106595e-21  -7.22014795e-21  -4.73169452e-22  -9.37945086e-21\n",
      "  -7.52388927e-21  -1.19182216e-20   2.14159348e-22   0.00000000e+00\n",
      "   3.42789686e-12  -2.43504202e-20   1.46067674e-20   6.03418061e-20\n",
      "  -3.38193595e-21  -3.33315743e-20  -9.08486921e-21  -6.14379498e-20\n",
      "  -1.30727720e-20  -1.61700214e-20   1.00792970e-19   3.64179578e-20\n",
      "  -5.08575807e-21   2.06315635e-20   5.46435520e-21  -1.39092132e-20\n",
      "  -1.01286520e-21  -1.82447904e-20  -1.53017472e-20  -2.38854436e-20\n",
      "   1.39408613e-23   1.30846459e-21  -1.11283478e-11   9.80120772e-12\n",
      "   3.50586048e-11  -2.62100452e-12  -7.82298947e-12  -4.13368718e-12\n",
      "  -3.45478771e-11  -3.61898463e-12   4.70185243e-12   2.72128155e-11\n",
      "   1.63889513e-11  -3.99559136e-12   1.60337405e-11   3.39957709e-12\n",
      "  -1.35965313e-11  -5.40179825e-13  -5.77844638e-12  -1.20149338e-11\n",
      "  -1.27480409e-11   3.37776195e-12  -2.43504202e-20   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.46067674e-20   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   6.03418061e-20   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -3.38193595e-21\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -3.33315743e-20   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -9.08486921e-21   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -6.14379498e-20\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -1.30727720e-20   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.61700214e-20   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.00792970e-19   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   3.64179578e-20   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -5.08575807e-21\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   2.06315635e-20   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   5.46435520e-21   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -1.39092132e-20\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -1.01286520e-21   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.82447904e-20   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.53017472e-20   0.00000000e+00\n",
      "   0.00000000e+00  -2.38854436e-20   0.00000000e+00   1.39408613e-23]\n",
      "Intercept: 0.49585652018539417\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: {0}\".format((model.get_params()['linearregression']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['linearregression']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По договоренности оптимальный коэффициент полиномиальной регрессии - 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 3.Применить и сравнить L1 и L2 регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ридж регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  3.31469998e-06  -5.84061406e-06  -1.47968227e-06   8.24357565e-07\n",
      "   5.44949555e-07   2.52559361e-06  -3.53875116e-08  -1.08859107e-06\n",
      "   9.72296847e-07  -4.55026374e-07  -1.29439025e-06  -1.02740846e-06\n",
      "   1.47574207e-06  -1.40138669e-06  -2.30021421e-06  -2.55033233e-06\n",
      "  -2.55198700e-06   2.90037314e-06  -3.55103470e-06  -5.08212670e-06\n",
      "   1.92823790e-06   4.10120228e-06   7.61748978e-07   1.33532777e-06\n",
      "   3.15800524e-06   5.55472525e-07   1.28741029e-11   2.73986228e-06\n",
      "  -1.79961020e-06  -4.09962074e-06   3.74591661e-08   1.75044918e-06\n",
      "   2.08584401e-06  -7.59715292e-06  -1.91147214e-06   1.50879687e-07\n",
      "   3.19995083e-06  -1.44447015e-06  -1.03138682e-06  -1.40691685e-06\n",
      "  -3.04306794e-06  -1.49515778e-06  -4.25434190e-06   1.87467339e-06\n",
      "   3.14932950e-06  -1.68096837e-06   2.71379905e-06  -2.44540393e-07\n",
      "   1.14390846e-07  -4.72287547e-06   2.73566475e-06   9.60942055e-07\n",
      "   5.77206457e-06   3.03101767e-06   6.26497321e-07  -3.98182620e-06\n",
      "   1.05444548e-06  -2.00381540e-06  -3.13669940e-07   3.54423925e-06\n",
      "  -1.21265785e-06  -3.04056980e-06  -3.23676732e-07  -1.15492175e-07\n",
      "   1.51595506e-07   1.62828121e-06  -4.96370356e-06   4.60389979e-06\n",
      "  -1.73192316e-06   3.28169988e-22  -9.38798201e-07  -9.38704216e-07\n",
      "  -9.38709208e-07  -9.38749744e-07  -9.38782916e-07  -9.38755319e-07\n",
      "  -9.38801966e-07  -9.38776221e-07  -9.38749849e-07  -9.38769365e-07\n",
      "  -9.38747492e-07  -9.38744898e-07  -9.38748131e-07  -9.38758618e-07\n",
      "  -9.38753919e-07  -9.38738390e-07  -9.38760850e-07  -9.38748255e-07\n",
      "  -9.38767470e-07  -9.38752965e-07  -2.30401529e-06  -3.33877769e-06\n",
      "   2.19899880e-06   7.71969023e-06   3.90445008e-06   2.20526668e-06\n",
      "  -1.56910970e-07  -5.23274180e-07   1.43083509e-06   2.36283543e-08\n",
      "  -4.89729681e-07   2.93457218e-06  -3.69576861e-06   5.93974202e-07\n",
      "  -1.52407798e-06  -1.53685055e-06   5.26766771e-06   3.61540794e-06\n",
      "   2.76422928e-07  -3.10272903e-06   1.03810548e-06  -1.41622226e-06\n",
      "  -2.22394129e-06   3.60807469e-06  -1.55161811e-07   3.25964204e-07\n",
      "   2.19655571e-06  -3.48475275e-06   1.98282286e-06   2.71442188e-06\n",
      "   4.71746557e-08   4.18984549e-06  -4.75229175e-06   5.74336936e-07\n",
      "  -3.81706280e-06   2.10439513e-06  -5.44288215e-07  -2.12788042e-06\n",
      "  -3.20479191e-06  -5.56330443e-06  -2.95719854e-07   2.69828445e-06\n",
      "  -4.56455435e-07  -5.22298228e-06  -2.80829690e-06  -1.09480605e-07\n",
      "   3.02268391e-06  -7.86840177e-06  -2.07135891e-06   1.90610301e-06\n",
      "   4.45565172e-06  -6.38511992e-07   4.05723438e-06  -3.52329256e-06\n",
      "  -4.55301313e-06   1.08607349e-06  -1.86396952e-08   1.05549680e-06\n",
      "   4.37946403e-06  -2.88246191e-06  -3.92304381e-06  -2.19427180e-07\n",
      "   1.71626326e-06  -2.53890151e-06   3.50875209e-06  -4.38967161e-06\n",
      "  -1.75393773e-06   1.51413501e-06   1.57290955e-06   2.95182661e-06\n",
      "   7.74370450e-06  -1.24450856e-06  -2.07589489e-06   3.29939007e-06\n",
      "   9.83786406e-07   2.30410327e-06   4.63081755e-06   1.51698078e-06\n",
      "   2.24242186e-06  -1.47502176e-06   3.31164721e-06   3.33992180e-06\n",
      "   1.30739911e-06   4.16051066e-07  -4.11563442e-06  -2.96932171e-06\n",
      "  -3.41818154e-06  -4.46574482e-06   2.96966377e-06  -1.22364348e-06\n",
      "   3.55548825e-06  -2.52266019e-06   5.99356656e-06  -2.03937312e-06\n",
      "   7.37998328e-07   3.66576849e-06   8.76871887e-07  -2.11569803e-06\n",
      "  -1.45446287e-06   1.66653350e-06  -2.51150146e-07  -2.45303892e-06\n",
      "  -8.10359083e-07  -1.45334213e-06   1.37543014e-06   3.81955935e-06\n",
      "  -4.99750449e-08   5.28368371e-07  -4.04036894e-06  -8.61483028e-07\n",
      "   2.01351514e-06   1.74258410e-06  -7.72287485e-07  -9.93679415e-08\n",
      "  -5.46294066e-06  -4.23707885e-07   1.15880658e-06  -1.82116477e-06\n",
      "   1.64056019e-06  -1.16091632e-07  -8.46952961e-08   3.09511769e-06\n",
      "   4.60308204e-06   5.32989012e-06  -1.73116899e-06  -4.06605215e-06\n",
      "   3.25010740e-06   1.65651796e-06  -1.17867251e-06  -1.05642791e-06\n",
      "   3.10826585e-06  -5.57611757e-06   2.59096404e-06   4.47107201e-06\n",
      "   1.52960875e-06  -4.52151086e-06   2.02107330e-06  -2.32624095e-06\n",
      "   2.61620992e-06  -8.64962392e-06  -3.52281340e-06  -1.96875329e-07\n",
      "  -3.13679437e-06  -3.39101531e-06  -2.35657099e-06  -9.55243412e-07\n",
      "   3.31781558e-06   5.28015848e-08  -4.15796539e-07   2.57954580e-07\n",
      "   1.86371781e-06   5.74544729e-06   5.16096266e-06  -2.17480039e-06\n",
      "  -3.16089640e-06   1.79029081e-06  -6.67904243e-06   3.79839225e-06\n",
      "   8.29974930e-07  -7.01384727e-07  -1.56369330e-06  -3.18970525e-06\n",
      "   2.65917343e-06  -1.89200941e-06  -1.18846345e-07   5.18915979e-07\n",
      "  -4.67084575e-06   3.12249522e-06   7.61919323e-07   4.49558325e-06\n",
      "   3.01914442e-06   2.08201113e-06  -1.65101871e-06  -6.46229321e-06\n",
      "   9.68908493e-07  -2.40998801e-07  -5.06033115e-07  -2.46925560e-06\n",
      "   2.27247321e-06   4.25499327e-06   1.77210202e-07   4.91715211e-06\n",
      "  -3.62497774e-07  -2.79465428e-06   1.39110623e-06   3.82743818e-06\n",
      "   5.70289092e-06   2.56159417e-06   5.87792224e-06   4.04579757e-06\n",
      "   3.92556712e-06  -9.77782910e-07  -8.88911320e-07   3.33340593e-06\n",
      "   5.12400041e-06  -4.90381673e-07  -3.26874968e-07   2.07189463e-06\n",
      "   2.24806062e-06  -1.27478948e-06  -2.79258295e-06  -2.64190496e-06\n",
      "   9.30328240e-07   1.30982470e-07  -2.54160418e-06  -5.08623750e-06\n",
      "  -3.15020074e-06   5.34320988e-06   7.61183076e-07  -1.08381743e-06]\n",
      "Intercept: 0.5001007316904245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "optimalDegree = 2\n",
    "\n",
    "# Будем использовать параметры по умолчанию, т.е. на данный момент не укажем значение alpha\n",
    "model = make_pipeline(PolynomialFeatures(2), Ridge())\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "MAE_list_Ridge = []\n",
    "MSE_list_Ridge = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list_Ridge.append(current_mae)\n",
    "    MSE_list_Ridge.append(current_mse)\n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лассо регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  0.00000000e+00   0.00000000e+00   0.00000000e+00  -7.34901766e-12\n",
      "  -0.00000000e+00  -0.00000000e+00  -0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00  -0.00000000e+00  -0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00  -0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   2.50152671e-14  -0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -1.26645570e-14  -0.00000000e+00  -0.00000000e+00  -0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00  -0.00000000e+00  -0.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "  -0.00000000e+00   5.45636761e-21  -4.59861957e-11  -3.13878824e-11\n",
      "   1.33054742e-11  -1.58612392e-11  -3.58450287e-11  -2.94853137e-11\n",
      "  -3.78115990e-11  -4.53964678e-11  -1.19504006e-11  -5.39088932e-11\n",
      "  -2.16149443e-11  -1.69663022e-11  -1.17698929e-11  -3.24927253e-11\n",
      "  -2.71724418e-11  -8.47098973e-12  -3.32848988e-11  -3.11116741e-11\n",
      "  -2.82354288e-11  -1.37962450e-11  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -0.00000000e+00]\n",
      "Intercept: 0.5186220165302344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(2), Lasso())\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "MAE_list_lasso = []\n",
    "MSE_list_lasso = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list_lasso.append(current_mae)\n",
    "    MSE_list_lasso.append(current_mse)   \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['lasso']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['lasso']).intercept_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE_ridge : 0.25010315131596483\n",
      "\tMSE_ridge : 0.08342070210783768\n",
      "\tRMSE_ridge : 0.28882642210822346\n",
      "\tMAE_Lasso : 0.2501035763394458\n",
      "\tMSE_Lasso : 0.08340375198737722\n",
      "\tRMSE_Lasso : 0.28879707752568623\n",
      "\tMAE_polin_degree2 : 0.2500668654270546\n",
      "\tMSE_polin_degree2 : 0.0833947607223043\n",
      "\tMAE_lin : 0.25007231423317544\n",
      "\tMSE_lin : 0.083387578119455\n",
      "Минимальное значение MSE - 0.083387578119455 у регрессии lin.\n",
      "Минимальное значение MAE - 0.2500668654270546 у регрессии polin_degree2.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tMAE_ridge : {0}\".format(np.mean(MAE_list_Ridge)))\n",
    "print(\"\\tMSE_ridge : {0}\".format(np.mean(MSE_list_Ridge)))\n",
    "print(\"\\tRMSE_ridge : {0}\".format(np.sqrt(np.mean(MSE_list_Ridge))))\n",
    "print(\"\\tMAE_Lasso : {0}\".format(np.mean(MAE_list_lasso)))\n",
    "print(\"\\tMSE_Lasso : {0}\".format(np.mean(MSE_list_lasso))) \n",
    "print(\"\\tRMSE_Lasso : {0}\".format(np.sqrt(np.mean(MSE_list_lasso))))\n",
    "print(\"\\tMAE_polin_degree2 : {0}\".format(maeList[2]))\n",
    "print(\"\\tMSE_polin_degree2 : {0}\".format(mseList[2]))\n",
    "print(\"\\tMAE_lin : {0}\".format(np.mean(MAE_list_scores)))\n",
    "print(\"\\tMSE_lin : {0}\".format(np.mean(MSE_list_scores)))\n",
    "min_list_MSE=[np.mean(MSE_list_Ridge),np.mean(MSE_list_lasso),MSE_polin_degree2,np.mean(MSE_list_scores)]\n",
    "min_list_MAE=[np.mean(MAE_list_Ridge),np.mean(MAE_list_lasso),MAE_polin_degree2,np.mean(MAE_list_scores)]\n",
    "dict1={0:'Ridge',1:'Lasso',2:'polin_degree2',3:'lin'}\n",
    "print(\"Минимальное значение MSE - {0} у регрессии {1}.\".format(min(min_list_MSE),dict1[min_list_MSE.index(min(min_list_MSE))]))\n",
    "print(\"Минимальное значение MAE - {0} у регрессии {1}.\".format(min(min_list_MAE),dict1[min_list_MAE.index(min(min_list_MAE))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что при кросс-валидации с количеством разбиений данных - 10, лучшие показатели у Лассо, а при 3 - простая линейная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При учете того, что оптимальноa признается 2 степень полинома, меньшее значение у метрик ошибочности модели\n",
    "(МSЕ и МАЕ),наблюдаетя у Лассо регуляризованной регрессии, связно это, как я полагаю, с высокой разряженностью созданной модели \n",
    "(многие веса как видно из массива коэфициентов приравниваются 0, в том числе и по причине слишком малого их значения).\n",
    "Я думаю, что лассо регрессия лучше справляется с этими данными, так как из за нулевых весов, \n",
    "она ближе к модели с 0 степенью полиномов. А сами по себе полиномиальные модели для этих данных не совсем релевантны, \n",
    "так как, видимо, слишком сложные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 4. Подобрать гиперпараметры для L1 и L2 регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "MSE_scorer = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_alphas = 200 # 200 значений\n",
    "alphas = np.logspace(-10, 2, n_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'alpha': alphas, 'fit_intercept' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-fc621c681eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mMSE_scorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Спустя минут 15 он все таки посчитал\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    725\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    468\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[1;32m    469\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 positive)\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(Lasso(), parameters, scoring  = MSE_scorer)\n",
    "clf.fit(X, y) #Спустя минут 15 он все таки посчитал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.083338198729262056"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.00018679135990207809, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Мы выяснили, что оптимальным значением степени для полиномиальной регрессии является 1, поэтому укажем её.\n",
    "optimalDegree = 2\n",
    "\n",
    "# передаем лучший estimator, подобранный с помощью GridSearchCV\n",
    "model = make_pipeline(PolynomialFeatures(2), clf.best_estimator_)\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list.append(current_mae)\n",
    "    MSE_list.append(current_mse)\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['lasso']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['lasso']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор параметра через MSE и MАE для Ridge регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAE_scorer_r = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "MSE_scorer_r = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200 # 200 значений\n",
    "alphas = np.logspace(-10, 2, n_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'alpha': alphas, 'fit_intercept' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-10,   1.14895e-10, ...,   8.70359e+01,   1.00000e+02]), 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(Ridge(), parameters, scoring  = MAE_scorer_r)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-10,   1.14895e-10, ...,   8.70359e+01,   1.00000e+02]), 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = GridSearchCV(Ridge(), parameters, scoring  = MSE_scorer_r)\n",
    "clf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100.0, 'fit_intercept': True}\n",
      "{'alpha': 100.0, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.250118362178\n",
      "-0.0834412970242\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=100.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=100.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.25014610400357334\n",
      "\tMSE : 0.08347285692040579\n",
      "Coefficients: [  3.58541464e-06   1.29032206e-06  -4.16629436e-06   1.63866324e-06\n",
      "  -3.19260085e-06   1.10115262e-06  -1.65891381e-06  -3.63971830e-06\n",
      "   5.51214207e-07  -2.88242867e-07   1.48018913e-06   4.88997544e-06\n",
      "   9.69223856e-07   3.43372255e-06  -5.98509212e-06  -2.42894353e-06\n",
      "   4.47819410e-06   2.59925954e-06  -8.72363523e-07  -1.94452386e-06\n",
      "   3.45914758e-06  -1.98963530e-06   4.44103751e-06   4.50556214e-07\n",
      "   3.60128835e-06  -1.40002364e-06   1.33239138e-12   1.57428329e-06\n",
      "  -1.57677725e-06   1.45432819e-06  -2.77690967e-06   2.62378582e-06\n",
      "   4.66945625e-08  -3.52142194e-06   3.10371287e-06   1.77262350e-06\n",
      "   1.83046660e-06  -6.41174565e-07   3.12235550e-06  -2.73800122e-06\n",
      "  -2.44870595e-06   4.83283077e-06  -4.18435920e-07   8.62150138e-07\n",
      "  -2.40510036e-06  -1.70220770e-06   1.70988034e-08  -1.48366055e-06\n",
      "  -2.44270070e-06  -8.55170628e-07  -5.03120472e-06  -4.86495925e-07\n",
      "   1.11759708e-07   1.36997588e-06   1.25478332e-06   6.51526963e-06\n",
      "  -1.34406749e-06  -2.59283708e-06  -5.79122235e-07  -9.31346742e-07\n",
      "   7.61637383e-07   4.85529072e-06  -1.71032792e-06  -9.39698848e-07\n",
      "  -2.46214487e-06   2.35069009e-06   2.15377697e-06   2.48924241e-06\n",
      "   4.87408856e-08   3.72895695e-21   8.03997206e-07   8.04011379e-07\n",
      "   8.04037023e-07   8.04013699e-07   8.03981379e-07   8.04010537e-07\n",
      "   8.03969242e-07   8.03994212e-07   8.04012562e-07   8.03961519e-07\n",
      "   8.04011892e-07   8.04014025e-07   8.04009528e-07   8.04019114e-07\n",
      "   8.04000200e-07   8.04014442e-07   8.03988317e-07   8.04016506e-07\n",
      "   8.03995907e-07   8.04023580e-07  -8.00870983e-07  -6.71229255e-06\n",
      "   1.46467073e-06   2.17320463e-07   3.63615769e-06   1.24021215e-06\n",
      "  -1.23515653e-06  -1.82696185e-06  -2.96846118e-06   4.24687654e-06\n",
      "   1.19322681e-06  -6.32015462e-06   3.99083642e-06  -7.64065406e-07\n",
      "  -1.26363329e-06   1.42200671e-06  -3.62996128e-07  -2.34122781e-06\n",
      "  -5.33965635e-06   2.15557815e-06  -2.79237099e-06   3.45629802e-06\n",
      "   1.10399772e-06  -1.75310354e-06  -1.37798940e-06   3.54870894e-07\n",
      "   1.77994615e-07   1.61310394e-06   6.42311488e-06   2.00318126e-06\n",
      "   6.14088158e-07   2.20594334e-06  -1.71214647e-06  -2.40852773e-06\n",
      "   2.02526761e-06   3.38618119e-06  -3.06590544e-06   1.14004861e-06\n",
      "   3.81447151e-07  -2.77619160e-07  -1.74438737e-06  -1.79423917e-06\n",
      "   3.26565803e-06  -6.54701837e-06  -1.03242465e-06  -1.16741822e-06\n",
      "   1.08057666e-06  -4.18487920e-06  -8.95803719e-07   4.67161288e-06\n",
      "   3.67306872e-06   7.11261970e-07   3.03837923e-06  -6.38092523e-06\n",
      "  -4.48619376e-06  -1.02896082e-06   4.54348169e-06  -2.73221035e-06\n",
      "   1.98599150e-07   1.50780805e-07  -2.73118056e-06  -3.98074057e-06\n",
      "  -4.63407041e-06   8.17138314e-07   5.02589538e-07  -9.19795701e-07\n",
      "  -1.20441566e-06   9.04975283e-07  -2.87576741e-06  -1.41951011e-06\n",
      "  -3.29425859e-06   2.72516150e-06   2.43091673e-06  -1.65187996e-07\n",
      "   2.04054442e-06  -9.89898586e-07  -2.15373656e-06  -2.56559685e-06\n",
      "   3.43078842e-06   1.00748157e-06  -1.67503067e-06  -1.24466406e-06\n",
      "   1.97263714e-06  -4.09196804e-06  -1.37139638e-06  -1.73363131e-06\n",
      "  -4.30410736e-06  -1.60129797e-06   1.29417745e-06   1.47635331e-06\n",
      "  -8.10744765e-07  -6.95141359e-06  -5.08613866e-06   7.94733779e-07\n",
      "   9.18884089e-09  -1.42553392e-06   5.45830882e-06   2.66700899e-06\n",
      "   2.66635203e-06  -1.95876972e-06   3.65841204e-06  -3.95335200e-07\n",
      "   2.32240244e-06  -2.29101224e-06   2.94882980e-06  -3.88496419e-06\n",
      "   6.19025046e-06  -1.61589165e-06  -2.53274134e-06  -6.20487314e-07\n",
      "   4.49555882e-07   1.23481255e-06   8.21815449e-06  -1.38873953e-06\n",
      "   4.85728811e-06   4.04650054e-07  -4.75469609e-07  -2.09237750e-06\n",
      "   1.42593640e-07   3.11053058e-06   1.43790848e-06   3.44884828e-07\n",
      "   1.58657618e-06  -3.68266352e-06  -5.43034616e-06  -2.49402368e-06\n",
      "  -1.58343846e-06   4.23296580e-06   2.26750387e-06  -8.97589674e-07\n",
      "   2.67492961e-06   1.06777408e-06   7.36951727e-07  -6.66466912e-07\n",
      "  -2.73776758e-06  -5.16078189e-06   3.00403040e-06  -2.09425842e-06\n",
      "  -2.45733032e-06   2.17342310e-07  -1.20141388e-06  -2.22838818e-06\n",
      "  -4.09131423e-06   3.03261024e-06   2.24608817e-06   2.08854197e-06\n",
      "   1.80297279e-06   1.65424787e-06   3.69054269e-06  -2.45739923e-06\n",
      "   3.63413470e-06  -1.79435227e-06   2.76219491e-06   4.02330022e-06\n",
      "   1.34817454e-06  -7.70759993e-06  -8.73820260e-07  -7.58123693e-07\n",
      "  -1.56259921e-06   4.98225834e-07  -4.17927324e-07   9.77703155e-07\n",
      "  -3.12622134e-06  -2.25957871e-07   8.52492526e-07  -5.87028278e-06\n",
      "  -1.52246111e-08  -2.06343078e-07  -1.18394227e-07  -2.29752479e-06\n",
      "  -2.70148575e-06  -1.98022810e-06   4.17322177e-06   1.84470619e-06\n",
      "  -1.24286327e-06  -5.28816801e-06   1.68283079e-06   1.14481671e-06\n",
      "   5.07569907e-06   1.21043590e-07  -2.65879420e-06   3.03275665e-06\n",
      "   1.59535706e-08   6.24939357e-06   4.03479367e-06  -2.33578687e-06\n",
      "  -5.00300842e-06   2.75296599e-06   4.09454720e-06   2.93944349e-06\n",
      "   1.51706856e-06   1.51414825e-06  -7.32483232e-06  -6.85581444e-07\n",
      "   1.05164724e-06  -6.84052177e-06   1.73292567e-06  -3.39540924e-07\n",
      "  -1.23532405e-06   3.39564104e-07   5.44799191e-07   5.53609087e-06\n",
      "  -1.25137243e-06  -5.94378439e-08   4.94808107e-06   1.52926268e-06\n",
      "  -2.70279585e-06  -2.72094849e-06  -6.34600519e-06  -8.54170293e-07]\n",
      "Intercept: 0.5195747998442978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "optimalDegree = 2\n",
    "\n",
    "# передаем лучший estimator, подобранный с помощью GridSearchCV\n",
    "model = make_pipeline(PolynomialFeatures(2), clf.best_estimator_)\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "MAE_list_po_MAE = []\n",
    "MSE_list_po_MAE = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list_po_MAE.append(current_mae)\n",
    "    MSE_list_po_MAE.append(current_mse)\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list_po_MAE)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list_po_MAE)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.2503541723768917\n",
      "\tMSE : 0.08366513591831816\n",
      "Coefficients: [  0.00000000e+00  -1.74744372e-03   0.00000000e+00  -1.56620531e-11\n",
      "  -9.85812670e-15  -3.42323017e-15  -1.00282538e-14   6.99602465e-15\n",
      "   3.57171162e-03  -2.48855232e-15  -4.06932225e-15  -9.78616709e-03\n",
      "   1.05744160e-03   1.16703247e-02  -1.00521022e-14   7.73037783e-15\n",
      "   4.03523711e-04   2.46000806e-04   1.76491423e-03  -6.89510522e-03\n",
      "   8.05793147e-03  -1.10755402e-14  -8.89133770e-04  -9.20144205e-03\n",
      "   5.69504738e-03  -1.74744372e-03   3.21334809e-12   6.13069962e-03\n",
      "   2.27187451e-03  -9.05734198e-03  -1.41052170e-02   8.47511592e-03\n",
      "   9.55710358e-03  -5.56021695e-02   1.00832265e-02   2.59224059e-03\n",
      "   1.30327943e-02  -7.61332344e-03   6.85168188e-03  -8.73806075e-03\n",
      "  -1.45217918e-02   1.55770601e-02  -2.16757847e-03  -8.75990980e-05\n",
      "  -2.50609711e-03  -9.25870508e-04   3.90058089e-02   0.00000000e+00\n",
      "  -1.67079566e-11  -1.00246590e-14  -3.44023379e-15  -4.93797408e-15\n",
      "   3.57090612e-16   3.57171162e-03  -2.37783374e-15  -4.57020787e-15\n",
      "  -9.78616709e-03   1.05744160e-03   1.16703247e-02  -1.14510160e-14\n",
      "   6.55133620e-15   4.03523711e-04   2.46000806e-04   1.76491423e-03\n",
      "  -6.89510522e-03   8.05793147e-03  -7.34169258e-15  -8.89133770e-04\n",
      "  -9.20144205e-03   4.73701826e-21  -1.27965495e-11   1.03925070e-11\n",
      "   4.07810841e-11   2.35712426e-11  -4.49303010e-11  -1.14853038e-11\n",
      "   3.35396143e-11   4.32603169e-11   1.22887392e-11  -1.56752943e-10\n",
      "   2.67887535e-11   9.75402661e-12   2.32102821e-11   2.37739544e-11\n",
      "  -9.82477183e-13   3.80106818e-11  -4.24253825e-11   1.64594121e-11\n",
      "   8.04898566e-12   3.68605639e-11  -5.40021069e-15   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -3.09914432e-15   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   8.32983795e-15   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -1.70942826e-15\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   3.57171162e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "  -3.80225358e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.71555142e-15\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -9.78616709e-03   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.05744160e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.16703247e-02   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -1.25538112e-14   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   6.96601892e-15\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   4.03523711e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   2.46000806e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.76491423e-03\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -6.89510522e-03   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   8.05793147e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.43990770e-14   0.00000000e+00\n",
      "   0.00000000e+00  -8.89133770e-04   0.00000000e+00  -9.20144205e-03]\n",
      "Intercept: 0.5105516669628527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "optimalDegree = 2\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(2), clf1.best_estimator_)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "MAE_list_po_MSE = []\n",
    "MSE_list_po_MSE = []\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list_po_MSE.append(current_mae)\n",
    "    MSE_list_po_MSE.append(current_mse)\n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list_po_MSE)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list_po_MSE)))    \n",
    "\n",
    "print(\"Coefficients: {0}\".format((model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE по МАЕ : 0.25014610400357334\n",
      "\tMSE по МАЕ : 0.08347285692040579\n",
      "\tMAE по МСЕ: 0.2503541723768917\n",
      "\tMSE по МСЕ: 0.08366513591831816\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tMAE по МАЕ : {0}\".format(np.mean(MAE_list_po_MAE)))\n",
    "print(\"\\tMSE по МАЕ : {0}\".format(np.mean(MSE_list_po_MAE)))\n",
    "print(\"\\tMAE по МСЕ: {0}\".format(np.mean(MAE_list_po_MSE)))\n",
    "print(\"\\tMSE по МСЕ: {0}\".format(np.mean(MSE_list_po_MSE)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как у лассо регресси много весов \"underflow\",  то для нее был посчитан один гипер параметр по MSE\n",
    "(выдает ошибку при каждой обработке нового значения w)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При сравнеии значений метрик MSE и MAE у ридж регресси с подобранным параметром выявлено, что параметр, \n",
    "найденный по MAE, позволяет лучше описать выборкую. Cтоит отметить также, что по второму параметру получилосьдостаточно много \n",
    "коэффициентов приравненных к 0, однако и это не спасло и без стого слишком сложную модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.Подбор гиперпараметров для L1 или L2 полиномиальной регрессии (со значением степени полученной из задачи 2). Получить значения метрик MAE, MSE, RMSE и весовых коэффициентов для оптимального параметра. Объяснить полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'ridge__alpha': alphas, 'ridge__fit_intercept' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6b6fe1d565a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mMSE_scorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 return_intercept=False)\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_intercept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept)\u001b[0m\n\u001b[1;32m    430\u001b[0m             raise TypeError('SVD solver does not support sparse'\n\u001b[1;32m    431\u001b[0m                             ' inputs currently')\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_solve_svd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36m_solve_svd\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0ms_nnz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mUTy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_nnz\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ms_nnz\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0md_UT_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mUTy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(model, parameters, scoring  = MSE_scorer)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2224572895.3788795"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE : 0.5159638181951166\n",
      "\tMSE : 0.3545462092901448\n",
      "Coefficients: [  8.76804766e-04   1.02737687e-06   4.54087461e-06   2.20421059e-06\n",
      "   5.58995898e-06   2.47046586e-06  -1.58148891e-06   2.59490587e-06\n",
      "  -2.44302530e-06   4.21882652e-06  -8.48378569e-07   1.54973299e-06\n",
      "  -2.86824047e-06  -4.12240799e-06   3.73538231e-06  -3.09748336e-06\n",
      "  -4.43868439e-06   1.15672440e-06   7.12184488e-07  -1.50093539e-06\n",
      "   5.26378210e-06   1.94785144e-06  -1.13767361e-07  -1.74421257e-06\n",
      "  -2.15478101e-06   5.02052265e-06   8.30610439e-12   3.70165190e-06\n",
      "   2.60253198e-06  -3.53676896e-07  -2.70311977e-06   8.70796017e-07\n",
      "   4.18046462e-06  -4.42147931e-06   2.08703320e-06  -3.29928570e-07\n",
      "   7.93077096e-08  -4.30977613e-06   6.32985931e-08  -6.93493534e-07\n",
      "   4.35471481e-07  -9.66763210e-07   3.34710036e-07   6.67633017e-07\n",
      "  -4.22907469e-06   2.70437189e-06   4.59003645e-06   1.51283525e-06\n",
      "  -1.52006475e-06   2.88837870e-06   2.23765011e-06   1.06967591e-06\n",
      "  -1.86400048e-06   2.48436028e-06  -3.30175931e-06  -2.53342524e-06\n",
      "  -1.62744354e-06  -4.54938623e-06   3.63647239e-06  -9.31315120e-08\n",
      "   6.07271195e-07  -2.34216528e-06   1.20450363e-06   1.70186330e-06\n",
      "  -2.48281396e-06   8.96434048e-07  -5.60732443e-06  -1.51949503e-06\n",
      "   2.07626618e-06   6.02425756e-21  -6.84175536e-07  -6.84173806e-07\n",
      "  -6.84141512e-07  -6.84156383e-07  -6.84169763e-07  -6.84169152e-07\n",
      "  -6.84197152e-07  -6.84179860e-07  -6.84162446e-07  -6.84176674e-07\n",
      "  -6.84145522e-07  -6.84162396e-07  -6.84152003e-07  -6.84162119e-07\n",
      "  -6.84168109e-07  -6.84158052e-07  -6.84163176e-07  -6.84157595e-07\n",
      "  -6.84173022e-07  -6.84150700e-07   3.67638294e-06  -2.16291370e-06\n",
      "  -3.64400450e-06  -4.57635083e-07   2.65639966e-06   3.37542576e-06\n",
      "  -4.31309804e-06  -2.60860718e-06   6.67421494e-06   3.58077574e-06\n",
      "   2.55784936e-06  -1.95689975e-06   2.56246250e-06  -5.31053403e-07\n",
      "  -4.29489340e-07  -2.37695546e-06   1.33268282e-06  -2.47215685e-06\n",
      "  -2.39368813e-06   1.15487212e-06   1.39405032e-06  -5.19395020e-06\n",
      "  -1.64596811e-06  -3.66141642e-06   1.72525334e-06   2.73294080e-06\n",
      "  -6.04886435e-07   1.13058663e-06  -1.24815381e-06   1.92391548e-06\n",
      "   2.00377708e-06  -2.20938614e-06   3.35638634e-06  -1.46374533e-06\n",
      "  -1.30834076e-06   2.77078231e-06   3.04496371e-06  -1.60400988e-06\n",
      "  -5.59494196e-07  -1.01329427e-06   5.38131199e-06   1.63203939e-06\n",
      "  -4.96657977e-06  -1.95819996e-06  -2.59297684e-06  -1.49115766e-06\n",
      "   2.07574880e-06   9.18189973e-07   1.27567073e-06   1.70416820e-06\n",
      "  -7.15830842e-07  -1.72771753e-06  -3.19159350e-06  -2.98898846e-06\n",
      "  -3.67409402e-06  -3.29450853e-06  -7.75983303e-07   5.27489913e-07\n",
      "  -2.60856268e-07   2.45996120e-06  -1.57071270e-06   2.45897336e-06\n",
      "  -1.02921577e-07  -2.76295467e-06  -7.35766266e-06   3.33652750e-08\n",
      "  -2.92173473e-06  -3.56420711e-06  -1.64985334e-06  -4.99463135e-07\n",
      "  -5.78493492e-07  -3.01732210e-06   9.92109259e-07   1.63736624e-06\n",
      "  -4.28692038e-06  -2.27565241e-06   2.02338412e-07   3.14426399e-06\n",
      "  -4.97440519e-07   1.70798069e-06  -3.86495206e-06   2.20708006e-06\n",
      "  -2.00708056e-06   1.44832477e-06  -2.33133286e-06  -2.37251035e-06\n",
      "  -3.19225239e-06  -2.59426830e-06   6.04984810e-06   1.26800036e-06\n",
      "   5.99246461e-06  -1.52283848e-06  -8.64733823e-07  -4.43594167e-06\n",
      "   8.56289296e-08  -2.49946803e-06   1.60905699e-06  -1.99720643e-07\n",
      "   2.72276111e-06   1.58576555e-06   1.56290639e-06   1.85217221e-07\n",
      "   3.06825549e-06  -2.17126392e-06  -1.78513689e-06  -5.21532017e-07\n",
      "   1.52726154e-07   3.18059383e-06   1.55127072e-06  -3.15522271e-06\n",
      "   1.76765462e-06   2.08617592e-06   7.14104588e-06  -3.38999406e-06\n",
      "  -2.12278657e-06  -1.65943341e-06  -2.49761673e-06   1.62190411e-07\n",
      "   1.11358613e-06  -1.10942503e-07  -3.47653766e-06   1.81373554e-06\n",
      "  -2.35034155e-06  -4.69424548e-06  -2.52327911e-06  -1.91245923e-06\n",
      "  -3.46670628e-07  -1.23746246e-06  -1.60890835e-06  -1.18160303e-06\n",
      "  -6.72268677e-06  -3.23373915e-06   2.38911633e-06  -2.19598166e-06\n",
      "  -5.70326910e-07   3.59154232e-06  -4.58407567e-06  -1.58047746e-06\n",
      "  -3.36201011e-06  -3.05523193e-06   8.17689097e-08   1.22416247e-06\n",
      "   2.23107441e-06   4.72997554e-06   1.98970410e-07  -7.53250679e-07\n",
      "  -3.30761922e-06   4.39283634e-07  -2.19567191e-06  -1.64155786e-06\n",
      "  -3.74850901e-06   2.68241040e-07  -2.03572487e-06  -1.50597735e-06\n",
      "  -1.22862958e-06  -5.36743729e-06   8.83259834e-07  -4.27726976e-07\n",
      "   3.98456908e-07  -2.44138034e-06   3.49978195e-06   4.77578816e-06\n",
      "   1.94913832e-06  -4.69201331e-07  -1.35075770e-06  -9.42311178e-07\n",
      "  -1.48642535e-06  -2.51221519e-06   2.49824196e-06  -5.60441344e-07\n",
      "   3.77179533e-07  -2.10458374e-06   1.47661851e-06  -7.37190673e-06\n",
      "   1.68587519e-06   4.54859281e-07  -1.24341993e-07  -2.93174809e-06\n",
      "   2.45786989e-06   1.72160644e-06  -1.12313575e-06  -1.05821859e-06\n",
      "  -6.00761362e-06   2.28186155e-06   5.23605640e-06  -3.97263337e-06\n",
      "   3.21533289e-06   2.35389903e-07   2.81515970e-06   1.32754930e-06\n",
      "  -1.57820741e-07  -3.03646804e-06  -1.89642264e-06  -3.09724993e-06\n",
      "  -4.25728446e-06  -2.66525675e-06  -1.55192334e-06  -2.08140900e-06\n",
      "   5.65103909e-07  -9.28109063e-07  -8.69882303e-07   1.13302790e-06\n",
      "   1.34679894e-06  -1.86353654e-06   1.85833862e-07  -5.79464139e-07\n",
      "  -6.27309444e-06   3.79066471e-06   3.71343094e-07  -1.27205186e-06]\n",
      "Intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "# передаем лучший estimator, подобранный с помощью GridSearchCV\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "new_model = clf.best_estimator_\n",
    "\n",
    "for train_indexes, test_indexes in kf.split(X,y):\n",
    "    # X_train, y_train - данные, соответствующие обучающей выборке\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    # X_test, y_test - данные, соответствующие тренировочной выборке\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "    \n",
    "    new_model.fit(X_train, y_train) # Обучение на тестовых данных\n",
    "    y_predict = new_model.predict(X_test)\n",
    "        \n",
    "    current_mae = mean_absolute_error(y_test, y_predict)\n",
    "    current_mse = mean_squared_error(y_test, y_predict)\n",
    "        \n",
    "    MAE_list.append(current_mae)\n",
    "    MSE_list.append(current_mse)\n",
    "    \n",
    "print(\"\\tMAE : {0}\".format(np.mean(MAE_list)))\n",
    "print(\"\\tMSE : {0}\".format(np.mean(MSE_list)))    \n",
    "print(\"\\tRMSE : {0}\".format(np.sqrt(np.mean(MSE_list)))) \n",
    "print(\"Coefficients: {0}\".format((new_model.get_params()['ridge']).coef_))\n",
    "print(\"Intercept: {0}\".format((new_model.get_params()['ridge']).intercept_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "По итогу полученных результатов регуляризованные регрессии на этих данных \"выигрывают\" очень небольшой\n",
    "процент меньшего совершения ошибки, однако он есть. Тем не менее лучше всего описывает выборку линейная регрессия, \n",
    "полагем из-за самой приророды данных - постоянства при расходе электроэнергии. Полиномиальные модели слишком сложные\n",
    "и тяготеют к переобучению. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
