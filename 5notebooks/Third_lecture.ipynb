{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем вместе все что мы имеем и реарганизуем это в чуть более сложные структуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "negative_tweets = open('negative_tweets.txt', 'r').readlines()[:1000]\n",
    "positive_tweets = open('positive_tweets.txt', 'r').readlines()[:1000]\n",
    "\n",
    "def find_unique_words(tweets):\n",
    "    clear_tweets = []\n",
    "    words = []\n",
    "    pattern = re.compile('[а-яА-Я]+')\n",
    "    for tweet in tweets:\n",
    "        res = re.findall(pattern, tweet)\n",
    "        clear_tweets.append(' '.join(res))\n",
    "        words.extend(res)\n",
    "    words = set(words)\n",
    "    return clear_tweets, words\n",
    "\n",
    "clear_pos_tweets, pos_words = find_unique_words(positive_tweets)\n",
    "clear_neg_tweets, neg_words = find_unique_words(negative_tweets)\n",
    "inter = pos_words.intersection(neg_words)\n",
    "pos_words = pos_words - inter\n",
    "neg_words = neg_words - inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы имеем два независмых набора слов, мы можем попытаться оценить новые твиты с их помощью. Это будет наша тестовая выборка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nt = open('negative_tweets.txt', 'r').readlines()[1000:1025]\n",
    "test_pt = open('positive_tweets.txt', 'r').readlines()[1000:1025]\n",
    "test_cpt, _ = find_unique_words(test_pt)\n",
    "test_cnt, _ = find_unique_words(test_nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть небольшая тествая выборка из 50 примеров, где и положительных и отрицательных твитов поровну. Постараемся оценить эти твиты по среднему значению. Разделим твиты на слова и если слово является маркером положительным добавим к оценке 1, если отрицательным отнимем единицу и чтобы привести все к интервалу от 0 до 1, будем делить на количество слов в предложении. Что и происходит в нижеследующем коде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07692307692307693, 0.0, 0.09090909090909091, 0.0, 0.0, -0.06666666666666667, 0.0, 0.25, -0.16666666666666666, -0.18181818181818182, 0.0, -0.16666666666666666, -0.3333333333333333, -0.17647058823529413, 0.0, 0.0, -0.14285714285714285, 0.0, 0.0, 0.0, -0.25, -0.1, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 1.0, 0.14285714285714285, -0.08333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, -0.09090909090909091, 0.0, 0.0, 0.0, 0.0, -0.07142857142857142, -0.1111111111111111, 1.0, -0.5, 1.0, 0.5, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def measure_score(test):\n",
    "    score_list=[]\n",
    "    for tweet in test:\n",
    "        score = 0\n",
    "        for word in tweet.split(' '):\n",
    "            if word in pos_words:\n",
    "                score+=1\n",
    "            elif word in neg_words:\n",
    "                score-=1\n",
    "        score/=len(tweet.split(' '))\n",
    "        score_list.append(score)\n",
    "    return score_list\n",
    "\n",
    "scores_pos = measure_score(test_cpt)\n",
    "scores_neg = measure_score(test_cnt)\n",
    "print(scores_neg, scores_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем отметить, большинство твитов не имеем никакого коэфицента. Давайте попробуем объяснить почему так произошло и какими простыми методами мы можем поправить эту ситауцию?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive, True Negative, False Positive, False Negative, Accuracy and Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши устные оценки хороши, однако неплохо бы привести к обще известным метрикам и в целом понять как они устроены. В конце концов нам нужно меть возможность не только сравнивать свои модели, но и модели уже существующие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://cdn-images-1.medium.com/max/1600/1*CPnO_bcdbE8FXTejQiV2dg.png' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вернемся к нашей задаче, что мы будем считать:\n",
    "<br> *True Positive*\n",
    "<br> *True Negative*\n",
    "<br> *False Positive*\n",
    "<br> *False Negative*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас у нас есть два списка с предсказанными значениями, и а так как мы знаем какие твиты позитивные, а какие нет, что может создать еще два списка с *истинными* значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "true_pos_scores = [1 for i in range(25)] #заодно познакомимся с вложенным списками и простой их генерацией в питоне\n",
    "true_neg_scores = [-1 for i in range(25)]\n",
    "print(true_neg_scores, true_pos_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В идеале наши модель должна генерировать именно такие знаения. Чувствуете разницу? Но будем к ней так критичны и решим так: если предсказанное значение больше 0, значит модель считает твит позитивным, если меньше 0 - негативным. Пройдемся по предсказанным значениям и посчитаем сколько же мы имеем TP, TN, FP and FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "TP= len([1 for i in scores_pos if i>0]) \n",
    "TN= len([1 for i in scores_neg if i<0])\n",
    "FP= len([1 for i in scores_neg if i>0])\n",
    "FN= len([1 for i in scores_pos if i<0])\n",
    "print((TP+TN+FP+FN)/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы считаете, что показывает нам это значение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на то, что модель не смогла предсказать значения для всех твитов, мы можем посчитать точность и полноту.\n",
    "<img src='https://www.shmula.com/wp-content/uploads/2010/05/accuracy-precision-msa-shmula.jpg' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного формул:\n",
    "$$Accuracy = (TP+TN)/(TP+TN+FP+FN)$$\n",
    "$$Precision = TP/(TP+FP)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7083333333333334 Precision:  0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "prec = (TP)/(TP+FP)\n",
    "print('Accuracy: ', accuracy, 'Precision: ', prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохие результаты, если не считать, что в половину твитов мы не оценили никаким образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
